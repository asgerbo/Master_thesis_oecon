{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FX_DAILY USD/EUR - daily\n",
    "# Crude oil prices - daily\n",
    "# REAL_GDP - quarterly\n",
    "# TREASURY_YIELD (Maturity = 3M, 10Y(10Y-3M), 30Y(30Y-3M)) - daily\n",
    "# FEDERAL_FUNDS_RATE - daily\n",
    "# CPI - monthly\n",
    "# INFLATION - monthly\n",
    "# UNEMPLOYMENT - monthly\n",
    "# Technical indicator - own functions derived from closing price of FX_DAILY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EURO VIX** -> [STOXX](https://stoxx.com/index/v2tx/)\n",
    "**US VIX** -> [CBOE](https://www.cboe.com/tradable_products/vix/vix_historical_data/)\n",
    "**EU Unemployment rate, GDP, CPI** -> [OECD](https://data-explorer.oecd.org)\n",
    "**US Unemployment** -> [FRED](https://fred.stlouisfed.org)\n",
    "**Trade balance** -> US: [FRED](https://fred.stlouisfed.org/series/IEABC), EU: [OECD Data](https://data-explorer.oecd.org/vis?tm=balance%20of%20payments&pg=0&snb=27&df[ds]=dsDisseminateFinalDMZ&df[id]=DSD_BOP%40DF_BOP&df[ag]=OECD.SDD.TPS&df[vs]=1.0&pd=2004-Q1%2C&dq=EA20..CA...Q.XDC.N&ly[cl]=TIME_PERIOD&ly[rs]=ACCOUNTING_ENTRY&to[TIME_PERIOD]=false)\n",
    "**Consumer Confidence Index** -> EU: [FRED](https://fred.stlouisfed.org/series/CSCICP03EZM665S), US: [FRED](https://fred.stlouisfed.org/series/CSCICP03USM665S)\n",
    "**M2** -> US: [FRED](https://fred.stlouisfed.org/series/M2SL), EU: [OECD Data](https://data.ecb.europa.eu/data/datasets/BSI/BSI.M.U2.N.V.M20.X.1.U2.2300.Z01.Echart_props=W3sibm9kZUlkIjoiNTk1NzciLCJwcm9wZXJ0aWVzIjpbeyJjb2xvckhleCI6IiIsImNvbG9yVHlwZSI6IiIsImNoYXJ0VHlwZSI6ImxpbmVjaGFydCIsImxpbmVTdHlsZSI6IlNvbGlkIiwibGluZVdpZHRoIjoiMS41IiwiYXhpc1Bvc2l0aW9uIjoibGVmdCIsIm9ic2VydmF0aW9uVmFsdWUiOmZhbHNlLCJkYXRlcyI6WyIyMDA0LTAyLTI5VDIzOjAwOjAwLjAwMFoiLCIyMDI0LTAzLTMwVDIzOjAwOjAwLjAwMFoiXSwiaXNUZGF0YSI6ZmFsc2UsIm1vZGlmaWVkVW5pdFR5cGUiOiIiLCJ5ZWFyIjoiZGF0ZXdpc2UiLCJzdGFydERhdGUiOiIyMDA0LTAzLTAxIiwiZW5kRGF0ZSI6IjIwMjQtMDMtMzEiLCJzZXREYXRlIjp0cnVlLCJzaG93VGFibGVEYXRhIjp0cnVlLCJjaGFuZ2VNb2RlIjpmYWxzZSwic2hvd01lbnVTdHlsZUNoYXJ0IjpmYWxzZSwiZGlzcGxheU1vYmlsZUNoYXJ0Ijp0cnVlLCJzY3JlZW5TaXplIjoibWF4Iiwic2NyZWVuV2lkdGgiOjE1MTIsInNob3dUZGF0YSI6ZmFsc2UsInRyYW5zZm9ybWVkRnJlcXVlbmN5Ijoibm9uZSIsInRyYW5zZm9ybWVkVW5pdCI6Im5vbmUiLCJmcmVxdWVuY3kiOiJub25lIiwidW5pdCI6Im5vbmUiLCJtb2RpZmllZCI6ImZhbHNlIiwic2VyaWVzS2V5IjoibW9udGhseSIsInNob3d0YWJsZVN0YXRlQmVmb3JlTWF4U2NyZWVuIjpmYWxzZSwiaXNkYXRhY29tcGFyaXNvbiI6ZmFsc2UsInNlcmllc0ZyZXF1ZW5jeSI6Im1vbnRobHkiLCJpbnRpYWxTZXJpZXNGcmVxdWVuY3kiOiJtb250aGx5IiwibWV0YWRhdGFEZWNpbWFsIjoiMCIsImlzVGFibGVTb3J0ZWQiOmZhbHNlLCJpc1llYXJseVRkYXRhIjpmYWxzZSwicmVzcG9uc2VEYXRhRW5kRGF0ZSI6IjIwMjQtMDMtMzEiLCJpc2luaXRpYWxDaGFydERhdGEiOnRydWUsImlzRGF0ZXNGcm9tRGF0ZVBpY2tlciI6dHJ1ZSwiZGF0ZVBpY2tlckVuZERhdGUiOiIyMDI0LTAzLTMxIiwiaXNEYXRlUGlja2VyRW5kRGF0ZSI6dHJ1ZSwic2VyaWVza2V5U2V0IjoiIiwiZGF0YXNldElkIjoiMTQiLCJpc0NhbGxiYWNrIjpmYWxzZSwiaXNTbGlkZXJUZGF0YSI6dHJ1ZSwiaXNTbGlkZXJEYXRhIjp0cnVlLCJpc0luaXRpYWxDaGFydERhdGFGcm9tR3JhcGgiOnRydWUsImNoYXJ0U2VyaWVzS2V5IjoiQlNJLk0uVTIuTi5WLk0yMC5YLjEuVTIuMjMwMC5aMDEuRSIsInR5cGVPZiI6ImRvd25Mb2FkIn1dfV0%3D)\n",
    "**Euro Stoxx** -> Google Finance\n",
    "**USD/EUR exchange rate** -> [FRED](https://fred.stlouisfed.org/series/DEXUSEU)\n",
    "**Yield Curves** -> EU: [ECB](https://www.ecb.europa.eu/stats/financial_markets_and_interest_rates/euro_area_yield_curves/html/index.en.html), US: Alpha Vantage API\n",
    "**FED and ECB assets** -> US: [FRED](https://fred.stlouisfed.org/series/WALCL) **Updated every wednesday**, EU: [ECB](https://data.ecb.europa.eu/main-figures/investment-funds/assets-and-liabilities)\n",
    "**CPI** -> [Correct Dates Data](https://alfred.stlouisfed.org/release/downloaddates?rid=10) together with this: [US Bureau](https://www.bls.gov/cpi/news.htm)\n",
    "**Unemployment rate** -> [Unemployment Rate Announcements](https://www.bls.gov/bls/news-release/empsit.htm)\n",
    "\n",
    "# Missing Variables\n",
    "\n",
    "Producer price index (PPI) US and EU -  Can find for US but not for EU\n",
    "\n",
    "Capital flows - Can find for Euro Area but not for the US\n",
    "\n",
    "overnight deposit eu/usd **missing for both**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BRENT...\n",
      "BRENT data for the last 20 years has been downloaded and saved to 'brent_filtered.csv'.\n",
      "Fetching data for REAL_GDP...\n",
      "REAL_GDP data for the last 20 years has been downloaded and saved to 'real_gdp_filtered.csv'.\n",
      "Fetching data for TREASURY_YIELD_3M...\n",
      "TREASURY_YIELD_3M data for the last 20 years has been downloaded and saved to 'treasury_yield_3m_filtered.csv'.\n",
      "Fetching data for TREASURY_YIELD_10Y...\n",
      "TREASURY_YIELD_10Y data for the last 20 years has been downloaded and saved to 'treasury_yield_10y_filtered.csv'.\n",
      "Fetching data for TREASURY_YIELD_30Y...\n",
      "TREASURY_YIELD_30Y data for the last 20 years has been downloaded and saved to 'treasury_yield_30y_filtered.csv'.\n",
      "Fetching data for FEDERAL_FUNDS_RATE...\n",
      "FEDERAL_FUNDS_RATE data for the last 20 years has been downloaded and saved to 'federal_funds_rate_filtered.csv'.\n",
      "Fetching data for CPI...\n",
      "CPI data for the last 20 years has been downloaded and saved to 'cpi_filtered.csv'.\n",
      "Fetching data for UNEMPLOYMENT...\n",
      "UNEMPLOYMENT data for the last 20 years has been downloaded and saved to 'unemployment_filtered.csv'.\n",
      "Fetching data for SP500...\n",
      "SP500 data for the last 20 years has been downloaded and saved to 'sp500_filtered.csv'.\n",
      "All data series have been fetched and saved.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "\n",
    "# Function to fetch data from Alpha Vantage\n",
    "def fetch_alpha_vantage_data(function, interval=None, maturity=None, datatype='json', **params):\n",
    "    base_url = \"https://www.alphavantage.co/query\"\n",
    "    api_key = \"U025297QMVF56UD3\"  # Replace with your actual API key\n",
    "    params['apikey'] = api_key\n",
    "    params['function'] = function\n",
    "    if interval:\n",
    "        params['interval'] = interval\n",
    "    if maturity:\n",
    "        params['maturity'] = maturity\n",
    "    if datatype:\n",
    "        params['datatype'] = datatype\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if datatype == 'json':\n",
    "        data = response.json()\n",
    "    else:\n",
    "        data = response.text\n",
    "    return data\n",
    "\n",
    "# Function to filter data for the last 20 years\n",
    "def filter_last_20_years(data, date_key):\n",
    "    twenty_years_ago = datetime.now() - relativedelta(years=20)\n",
    "    if isinstance(data, list):  # When data is a list of dictionaries (e.g., 'data' key format)\n",
    "        filtered_data = [entry for entry in data if datetime.strptime(entry[date_key], '%Y-%m-%d') > twenty_years_ago]\n",
    "    else:  # When data is a dictionary (e.g., 'Time Series (Daily)' format)\n",
    "        filtered_data = {date: values for date, values in data.items() if datetime.strptime(date, '%Y-%m-%d') > twenty_years_ago}\n",
    "    return filtered_data\n",
    "\n",
    "# List of datasets to fetch\n",
    "datasets = [\n",
    "    {'name': 'BRENT', 'function': 'BRENT', 'params': {'interval': 'daily'}, 'date_key': 'date'},\n",
    "    {'name': 'REAL_GDP', 'function': 'REAL_GDP', 'params': {'interval': 'quarterly'}, 'date_key': 'date'},\n",
    "    {'name': 'TREASURY_YIELD_3M', 'function': 'TREASURY_YIELD', 'params': {'interval': 'daily', 'maturity': '3month'}, 'date_key': 'date'},\n",
    "    {'name': 'TREASURY_YIELD_10Y', 'function': 'TREASURY_YIELD', 'params': {'interval': 'daily', 'maturity': '10year'}, 'date_key': 'date'},\n",
    "    {'name': 'TREASURY_YIELD_30Y', 'function': 'TREASURY_YIELD', 'params': {'interval': 'daily', 'maturity': '30year'}, 'date_key': 'date'},\n",
    "    {'name': 'FEDERAL_FUNDS_RATE', 'function': 'FEDERAL_FUNDS_RATE', 'params': {'interval': 'daily'}, 'date_key': 'date'},\n",
    "    {'name': 'CPI', 'function': 'CPI', 'params': {'interval':'monthly'}, 'date_key': 'date'},\n",
    "    {'name': 'UNEMPLOYMENT', 'function': 'UNEMPLOYMENT', 'params': {}, 'date_key': 'date'},\n",
    "    {'name': 'SP500', 'function': 'TIME_SERIES_DAILY', 'params': {'symbol': 'SPY', 'outputsize': 'full'}, 'date_key': None},\n",
    "]\n",
    "\n",
    "# Loop through each dataset, fetch and save the data\n",
    "for dataset in datasets:\n",
    "    name = dataset['name']\n",
    "    function = dataset['function']\n",
    "    params = dataset['params']\n",
    "    date_key = dataset['date_key']\n",
    "    \n",
    "    print(f\"Fetching data for {name}...\")\n",
    "    data = fetch_alpha_vantage_data(function, **params)\n",
    "    time.sleep(12)  # To avoid hitting rate limits\n",
    "    \n",
    "    # For TIME_SERIES_DAILY, the data key is 'Time Series (Daily)'\n",
    "    if function == 'TIME_SERIES_DAILY' and 'Time Series (Daily)' in data:\n",
    "        raw_data = data['Time Series (Daily)']\n",
    "        filtered_data = filter_last_20_years(raw_data, date_key=None)\n",
    "        \n",
    "        # Convert filtered data to a DataFrame\n",
    "        data_df = pd.DataFrame.from_dict(filtered_data, orient='index')\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        csv_filename = f'{name.lower()}_filtered.csv'\n",
    "        data_df.to_csv(csv_filename, index=True)\n",
    "        print(f\"{name} data for the last 20 years has been downloaded and saved to '{csv_filename}'.\")\n",
    "    elif 'data' in data:\n",
    "        raw_data = data['data']\n",
    "        filtered_data = filter_last_20_years(raw_data, date_key)\n",
    "        \n",
    "        # Convert filtered data to a DataFrame\n",
    "        data_df = pd.DataFrame(filtered_data)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        csv_filename = f'{name.lower()}_filtered.csv'\n",
    "        data_df.to_csv(csv_filename, index=False)\n",
    "        print(f\"{name} data for the last 20 years has been downloaded and saved to '{csv_filename}'.\")\n",
    "    else:\n",
    "        print(f\"Key 'data' or 'Time Series (Daily)' not found in response for {name}. Full response: {data}\")\n",
    "\n",
    "print(\"All data series have been fetched and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USD/EUR exchange rate with open, high, low, close and volume are only for 10 years historical. Closing price is for 20 years though, therefore we cannot create some technical variables.  \n",
    "Quarterly and monthly variables without publication dates have been removed to remove look ahead bias.  \n",
    "Unemployment and inflation for both US and EU are historical data and not the data included in the ACTUAL publications (press release), therefore there is a small difference between these two values. Using historical versus actual publication values can yield different results, but using the historical publication dates gets us closer than using day 1 of each month as the data originally was in.  \n",
    "All dates without a correspoding target variable value have been removed.  \n",
    "All non-trading days are not existent within the dataset.  \n",
    "All variables are limited in the way that we have to use the oldest information available, therefore if one variable had markedly lower observations, that variable would set the cutoff point.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Data saved to usd_eur_exchange_rate_yahoo.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_forex_data(ticker='EURUSD=X', start_date='2004-01-01'):\n",
    "    \"\"\"\n",
    "    Fetch historical forex data from Yahoo Finance.\n",
    "    \"\"\"\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, start=start_date)\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    # Fetch the data\n",
    "    df = fetch_forex_data()\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv('usd_eur_exchange_rate_yahoo.csv')\n",
    "    print(\"Data saved to usd_eur_exchange_rate_yahoo.csv\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date      Open      High       Low     Close  Adj Close  Volume\n",
      "5284  2024-05-14  1.079354  1.082837  1.077644  1.079354   1.079354       0\n",
      "5285  2024-05-15  1.081455  1.087429  1.081362  1.081455   1.081455       0\n",
      "5286  2024-05-16  1.088981  1.089681  1.085517  1.088981   1.088981       0\n",
      "5287  2024-05-17  1.086779  1.087891  1.083635  1.086779   1.086779       0\n",
      "5288  2024-05-20  1.087193  1.088732  1.085776  1.086957   1.086957       0\n"
     ]
    }
   ],
   "source": [
    "# Inspect usd_eur_exchange_rate_yahoo.csv\n",
    "df = pd.read_csv('usd_eur_exchange_rate_yahoo.csv')\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for period starting 2003-01-01\n",
      "Fetching data for period starting 2003-04-11\n",
      "Fetching data for period starting 2003-07-20\n",
      "Fetching data for period starting 2003-10-28\n",
      "Fetching data for period starting 2004-02-05\n",
      "Fetching data for period starting 2004-05-15\n",
      "Fetching data for period starting 2004-08-23\n",
      "Fetching data for period starting 2004-12-01\n",
      "Fetching data for period starting 2005-03-11\n",
      "Fetching data for period starting 2005-06-19\n",
      "Fetching data for period starting 2005-09-27\n",
      "Fetching data for period starting 2006-01-05\n",
      "Fetching data for period starting 2006-04-15\n",
      "Fetching data for period starting 2006-07-24\n",
      "Fetching data for period starting 2006-11-01\n",
      "Fetching data for period starting 2007-02-09\n",
      "Fetching data for period starting 2007-05-20\n",
      "Fetching data for period starting 2007-08-28\n",
      "Fetching data for period starting 2007-12-06\n",
      "Fetching data for period starting 2008-03-15\n",
      "Fetching data for period starting 2008-06-23\n",
      "Fetching data for period starting 2008-10-01\n",
      "Fetching data for period starting 2009-01-09\n",
      "Fetching data for period starting 2009-04-19\n",
      "Fetching data for period starting 2009-07-28\n",
      "Fetching data for period starting 2009-11-05\n",
      "Fetching data for period starting 2010-02-13\n",
      "Fetching data for period starting 2010-05-24\n",
      "Fetching data for period starting 2010-09-01\n",
      "Fetching data for period starting 2010-12-10\n",
      "Fetching data for period starting 2011-03-20\n",
      "Fetching data for period starting 2011-06-28\n",
      "Fetching data for period starting 2011-10-06\n",
      "Fetching data for period starting 2012-01-14\n",
      "Fetching data for period starting 2012-04-23\n",
      "Fetching data for period starting 2012-08-01\n",
      "Fetching data for period starting 2012-11-09\n",
      "Fetching data for period starting 2013-02-17\n",
      "Fetching data for period starting 2013-05-28\n",
      "Fetching data for period starting 2013-09-05\n",
      "Fetching data for period starting 2013-12-14\n",
      "Fetching data for period starting 2014-03-24\n",
      "Fetching data for period starting 2014-07-02\n",
      "Fetching data for period starting 2014-10-10\n",
      "Fetching data for period starting 2015-01-18\n",
      "Fetching data for period starting 2015-04-28\n",
      "Fetching data for period starting 2015-08-06\n",
      "Fetching data for period starting 2015-11-14\n",
      "Fetching data for period starting 2016-02-22\n",
      "Fetching data for period starting 2016-06-01\n",
      "Fetching data for period starting 2016-09-09\n",
      "Fetching data for period starting 2016-12-18\n",
      "Fetching data for period starting 2017-03-28\n",
      "Fetching data for period starting 2017-07-06\n",
      "Fetching data for period starting 2017-10-14\n",
      "Fetching data for period starting 2018-01-22\n",
      "Fetching data for period starting 2018-05-02\n",
      "Fetching data for period starting 2018-08-10\n",
      "Fetching data for period starting 2018-11-18\n",
      "Fetching data for period starting 2019-02-26\n",
      "Fetching data for period starting 2019-06-06\n",
      "Fetching data for period starting 2019-09-14\n",
      "Fetching data for period starting 2019-12-23\n",
      "Fetching data for period starting 2020-04-01\n",
      "Fetching data for period starting 2020-07-10\n",
      "Fetching data for period starting 2020-10-18\n",
      "Fetching data for period starting 2021-01-26\n",
      "Fetching data for period starting 2021-05-06\n",
      "Fetching data for period starting 2021-08-14\n",
      "Fetching data for period starting 2021-11-22\n",
      "Fetching data for period starting 2022-03-02\n",
      "Fetching data for period starting 2022-06-10\n",
      "Fetching data for period starting 2022-09-18\n",
      "Fetching data for period starting 2022-12-27\n",
      "Fetching data for period starting 2023-04-06\n",
      "Fetching data for period starting 2023-07-15\n",
      "Fetching data for period starting 2023-10-23\n",
      "             Datetime     Open     High      Low    Close\n",
      "0 2024-03-26 10:00:00  0.92150  0.92170  0.92090  0.92110\n",
      "1 2024-03-26 11:00:00  0.92110  0.92110  0.92020  0.92090\n",
      "2 2024-03-26 12:00:00  0.92100  0.92100  0.92060  0.92080\n",
      "3 2024-03-26 13:00:00  0.92080  0.92150  0.92070  0.92130\n",
      "4 2024-03-26 14:00:00  0.92130  0.92160  0.92070  0.92110\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Function to fetch data from Alpha Vantage\n",
    "def fetch_alpha_vantage_data(function, from_symbol=None, to_symbol=None, interval=None, datatype='json', **params):\n",
    "    base_url = \"https://www.alphavantage.co/query\"\n",
    "    api_key = \"U025297QMVF56UD3\"  # Replace with your actual API key\n",
    "    params['apikey'] = api_key\n",
    "    params['function'] = function\n",
    "    if from_symbol and to_symbol:\n",
    "        params['from_symbol'] = from_symbol\n",
    "        params['to_symbol'] = to_symbol\n",
    "    if interval:\n",
    "        params['interval'] = interval\n",
    "    if datatype:\n",
    "        params['datatype'] = datatype\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if datatype == 'json':\n",
    "        data = response.json()\n",
    "    else:\n",
    "        data = response.text\n",
    "    return data\n",
    "\n",
    "# Function to fetch intraday data in chunks\n",
    "def fetch_alpha_vantage_intraday_chunks(api_key, from_symbol, to_symbol, interval, start_date, end_date):\n",
    "    all_data = []\n",
    "    current_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        print(f\"Fetching data for period starting {current_date.strftime('%Y-%m-%d')}\")\n",
    "        data = fetch_alpha_vantage_data(\n",
    "            function='FX_INTRADAY',\n",
    "            from_symbol=from_symbol,\n",
    "            to_symbol=to_symbol,\n",
    "            interval=interval,\n",
    "            outputsize='full'\n",
    "        )\n",
    "        \n",
    "        time.sleep(12)  # To avoid hitting rate limits\n",
    "        \n",
    "        if 'Time Series FX (60min)' in data:\n",
    "            time_series = data['Time Series FX (60min)']\n",
    "            df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "            df.columns = [\"Open\", \"High\", \"Low\", \"Close\"]  # Adjusted to reflect the actual columns available\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.sort_index(inplace=True)\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"Error: 'Time Series FX (60min)' not found in response for period starting {current_date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        current_date += timedelta(days=100)  # Move to the next chunk\n",
    "\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data)\n",
    "        final_df.reset_index(inplace=True)\n",
    "        final_df.rename(columns={\"index\": \"Datetime\"}, inplace=True)\n",
    "        return final_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "api_key = 'U025297QMVF56UD3'  # Replace with your actual API key\n",
    "start_date = '2003-01-01'\n",
    "end_date = '2023-12-31'\n",
    "df = fetch_alpha_vantage_intraday_chunks(api_key, 'USD', 'EUR', '60min', start_date, end_date)\n",
    "if df is not None:\n",
    "    df.to_csv('usd_eur_intraday_60min.csv', index=False)\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
