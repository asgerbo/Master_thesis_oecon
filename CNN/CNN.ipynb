{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data: 100%|██████████| 503/503 [01:21<00:00,  6.18it/s]\n",
      "Processing tickers: 100%|██████████| 438/438 [01:53<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the list of S&P 500 tickers\n",
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "tickers = sp500['Symbol'].tolist()\n",
    "\n",
    "vix = yf.Ticker('^VIX')\n",
    "vix_df = vix.history(period=\"15y\")\n",
    "vix_df = vix_df['Close']\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "max_days = 0  # Keep track of the maximum number of trading days\n",
    "\n",
    "# Retrieve market capitalization and P/E ratio for all tickers\n",
    "market_cap = []\n",
    "pe_ratio = []\n",
    "for ticker in tqdm(tickers, desc=\"Retrieving data\"):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        market_cap.append(stock.info['marketCap'])\n",
    "        pe_ratio.append(stock.info['trailingPE'])\n",
    "    except KeyError:\n",
    "        market_cap.append(np.nan)\n",
    "        pe_ratio.append(np.nan)\n",
    "\n",
    "# Filter out tickers with missing data\n",
    "valid_tickers = [ticker for i, ticker in enumerate(tickers) if not np.isnan(market_cap[i]) and not np.isnan(pe_ratio[i])]\n",
    "market_cap = [cap for i, cap in enumerate(market_cap) if not np.isnan(cap)]\n",
    "pe_ratio = [ratio for i, ratio in enumerate(pe_ratio) if not np.isnan(ratio)]\n",
    "\n",
    "# Loop through each valid ticker and download the data\n",
    "for ticker in tqdm(valid_tickers, desc=\"Processing tickers\"):\n",
    "    try:\n",
    "        # Download the data\n",
    "        stock = yf.Ticker(ticker)\n",
    "        df = stock.history(period=\"15y\")\n",
    "        \n",
    "        # Calculate RSI\n",
    "        delta = df['Close'].diff()\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)\n",
    "        avg_gain = gain.rolling(14).mean()\n",
    "        avg_loss = loss.rolling(14).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        df['RSI'] = rsi\n",
    "        \n",
    "        # Calculate Exponential Moving Averages\n",
    "        df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "        df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "        \n",
    "        # Add the market capitalization and P/E ratio\n",
    "        df['Market Cap'] = market_cap[valid_tickers.index(ticker)]\n",
    "        df['P/E Ratio'] = pe_ratio[valid_tickers.index(ticker)]\n",
    "        \n",
    "        # Restructure the data into a tensor format\n",
    "        tensor_data = df[['Open', 'High', 'Low', 'Close', 'Volume', 'RSI', 'EMA_12', 'EMA_26', 'VIX', 'Market Cap', 'P/E Ratio']].values\n",
    "        tensor_data = np.expand_dims(tensor_data, axis=1)\n",
    "        \n",
    "        # Update the maximum number of trading days\n",
    "        max_days = max(max_days, tensor_data.shape[2])\n",
    "        \n",
    "        data.append(tensor_data)\n",
    "    except:\n",
    "        # Skip any tickers that don't have data\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of uniform_tensor: (2799, 11, 11)\n"
     ]
    }
   ],
   "source": [
    "# tensor structure -> (samples, time steps, features), where samples is the no. of stocks, time steps is the trading days, and features is the data for each day. \n",
    "\n",
    "# Assuming the dimensions for uniform_tensor were intended to be:\n",
    "# (number_of_stocks, max_days, number_of_features)\n",
    "# and each stock_data in data has shape (days, 1, features) before squeeze\n",
    "\n",
    "number_of_stocks = len(tensor_data)  # 438 based on your update\n",
    "number_of_features = 11  # Based on the features you've described\n",
    "# Ensure max_days is correctly calculated as the maximum days across all datasets\n",
    "\n",
    "# Reinitialize uniform_tensor in case there's been a mistake in its setup\n",
    "uniform_tensor = np.full((number_of_stocks, max_days, number_of_features), np.nan)\n",
    "\n",
    "# Loop through each stock's data in 'data'\n",
    "for i, stock_data in enumerate(tensor_data):\n",
    "    # Squeeze to remove the singleton dimension, resulting in shape (days, features)\n",
    "    stock_data_squeezed = stock_data.squeeze()\n",
    "    # Number of days corresponds to the first dimension of the squeezed data\n",
    "    num_days = stock_data_squeezed.shape[0]\n",
    "\n",
    "    # This operation should work given the shapes involved\n",
    "    uniform_tensor[i, :num_days, :] = stock_data_squeezed\n",
    "\n",
    "# Verify the shape of uniform_tensor to ensure it's as expected\n",
    "print(f\"Shape of uniform_tensor: {uniform_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2799\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting data from FRED\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "\n",
    "# Download the data\n",
    "start = datetime.datetime(2000, 1, 1)\n",
    "end = datetime.datetime(2021, 1, 1)\n",
    "gdp = pdr.get_data_fred('GDP', start, end)\n",
    "unemployment = pdr.get_data_fred('UNRATE', start, end)\n",
    "cpi = pdr.get_data_fred('CPIAUCSL', start, end)\n",
    "consumer_confidence = pdr.get_data_fred('UMCSENT', start, end)\n",
    "m1 = pdr.get_data_fred('M1', start, end)\n",
    "m2 = pdr.get_data_fred('M2', start, end)\n",
    "ten_year = pdr.get_data_fred('GS10', start, end)\n",
    "thirty_year = pdr.get_data_fred('GS30', start, end)\n",
    "\n",
    "# Federal Reserve Bank of St. Louis: Wilshire 5000 Price Index\n",
    "# Federal Reserve Bank of St. Louis: US Gross Domestic Product"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
